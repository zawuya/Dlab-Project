{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMGpdvNd12vhGKUnyu9GF75",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zawuya/Dlab-Project/blob/master/imbalancedata1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U imbalanced-learn\n",
        "! pip install -U scikit-learn"
      ],
      "metadata": {
        "id": "ZUWCGH6qApH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LuFCE-hfU0s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.cross_validation import train_test_split\n",
        "import joblib # saving models\n",
        "import os #creating folders\n",
        "\n",
        "from collections import Counter #counting data\n",
        "import collections\n",
        "from imblearn.over_sampling import SMOTE #Balancing data\n",
        "\n",
        "import imblearn\n",
        "#Split arrays or matrices into random train and test subsets\n",
        "\n",
        "# import library\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# import library\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re \n",
        "import os\n",
        "import joblib \n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import xgboost as xgb\n",
        "#import catboost as ctb\n",
        "import lightgbm as ltb\n",
        "import collections\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import plot_importance\n",
        "from xgboost import XGBClassifier\n",
        "#from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"telecom_TZ_sentiment_data2.csv\", dtype=str)\n",
        "data"
      ],
      "metadata": {
        "id": "x8MMC-Frv5CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing irrelevant value \"complains\"\n",
        "data.drop(data.loc[data['sentiment']=='complains'].index, inplace=True)"
      ],
      "metadata": {
        "id": "xkZsKFqLHJ_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicated data\n",
        "data.drop_duplicates(subset=['comment'], keep='first', inplace=True)"
      ],
      "metadata": {
        "id": "vsdRdzjXIfgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop nullvalues from the dataset\n",
        "data.dropna(subset=['sentiment', 'comment'], inplace=True)"
      ],
      "metadata": {
        "id": "d48_j6XhJXix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.count()"
      ],
      "metadata": {
        "id": "5PaipPCqJhNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a list of swahili stopwords used in the process\n",
        "swahili_stopwords = [\n",
        "    'akasema', 'alikuwa', 'alisema', 'baada', 'basi', 'bila', 'cha', 'chini',\n",
        "    'hadi', 'hapo', 'hata', 'hivyo', 'hiyo', 'huku', 'huo', 'ila', 'ili',\n",
        "    'ilikuwa', 'juu', 'kama', 'karibu', 'katika', 'kila', 'kima', 'kisha',\n",
        "    'kubwa', 'kutoka', 'kuwa', 'kwa', 'kwamba', 'kwenda', 'kwenye', 'la',\n",
        "    'lakini', 'mara', 'mdogo', 'mimi', 'mkubwa', 'mmoja', 'moja', 'muda',\n",
        "    'mwenye', 'na', 'naye', 'ndani', 'ni', 'nini', 'nonkungu', 'pamoja', 'pia',\n",
        "    'sana', 'sasa', 'sauti', 'tafadhali', 'tena', 'tu', 'vile', 'wa', 'wakati',\n",
        "    'wake', 'walikuwa', 'wao', 'watu', 'wengine', 'wote', 'ya', 'hivi', 'huu',\n",
        "    'hii', 'yake', 'yangu', 'yao', 'yeye', 'yule', 'vya', 'za', 't', 'co',\n",
        "    'tz', 'au', 'tanzania', 'zaidi', 'zake', 'si','mm','ndo','hapa','je','hawa','nyie'\n",
        "]"
      ],
      "metadata": {
        "id": "uD-2KmkuTN4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data_set(list_text):\n",
        "    new_list = []\n",
        "    stopwords_df = pd.read_csv(\"swahili_stopword.csv\", dtype=str, low_memory=False, encoding=\"utf-8\")\n",
        "    #stopwords_df = swahili_stopwords\n",
        "    stopwords_list = list(stopwords_df['StopWords'])\n",
        "    \n",
        "    for x in list_text:\n",
        "        x = re.sub(r'@[\\w]+','', str(x)) # remove twitter handle\n",
        "        x = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', str(x)) # removes Url\n",
        "        x = re.sub(r'[^\\w\\s]',' ', str(x))    # Remove Panctuations /?!. \n",
        "        x = x.strip()                   # Remove leading and trailing spaces\n",
        "        x = re.sub(' +', ' ', x)        # Remove extra white spaces\n",
        "        x = re.sub('[^A-Za-z0-9]+', ' ', x)  # Remove special characters\n",
        "        x = x.lower()                   # Converts to lower case\n",
        "        x = ' '.join([word for word in x.split() if word not in stopwords_list]) # Removes stopwords\n",
        "        new_list.append(x)\n",
        "    return new_list"
      ],
      "metadata": {
        "id": "9HtXRoevVwiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"clean_comment\"] = clean_data_set(data.comment.to_list())\n",
        "# assigning new value to hold clean comments obtained from the function"
      ],
      "metadata": {
        "id": "ie88Sw5cKZNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"clean_telecom_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "nleWztDMKQA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('clean_telecom_data.csv')\n",
        "data"
      ],
      "metadata": {
        "id": "oEpbHBAtM4W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign for data inputs and target set\n",
        "x=data['clean_comment']\n",
        "y=data['sentiment']"
      ],
      "metadata": {
        "id": "S_BiJs1WwYa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "Z0PiAoE0glrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset features\n",
        "x"
      ],
      "metadata": {
        "id": "E7LWQTdrHoHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#target class distribution\n",
        "y.value_counts()"
      ],
      "metadata": {
        "id": "owpOyv9Zw61J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show pie plot\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(y.value_counts(), autopct='%.2f', labels=data['sentiment'].value_counts())"
      ],
      "metadata": {
        "id": "c9zlqf3Uyr9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sns.displot(y))"
      ],
      "metadata": {
        "id": "mV7bZj0C4IHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=42)\n",
        "# fit predictor and target variable\n",
        "x_ros, y_ros = ros.fit_resample(x, y)"
      ],
      "metadata": {
        "id": "RVGNCM89XAtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show pie plot\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(y_ros.value_counts(), autopct='%.2f', labels=data['sentiment'].value_counts())"
      ],
      "metadata": {
        "id": "Jzy8HUj5YRo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_ros.value_counts()"
      ],
      "metadata": {
        "id": "TXyEJWMHg44h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original dataset before over sampling', Counter(y))\n",
        "print('Resample dataset after over sampling', Counter(y_ros))"
      ],
      "metadata": {
        "id": "Hx8oHS4nYs9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Splitting"
      ],
      "metadata": {
        "id": "BTkEetc6ZG4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xb_train, Xb_test, yb_train, yb_test = train_test_split(x_ros, y_ros,test_size=0.2, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "RQ8PDqaHZGFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y,test_size=0.8, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "bu5DVvkOZNrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting into series"
      ],
      "metadata": {
        "id": "-6viOTaAZZvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xb_train = Xb_train.squeeze()\n",
        "Xb_test = Xb_test.squeeze()\n",
        "yb_train = yb_train.squeeze()\n",
        "yb_test = yb_test.squeeze()\n",
        "\n",
        "X_train = X_train.squeeze()\n",
        "X_test = X_test.squeeze()\n",
        "y_train = y_train.squeeze()\n",
        "y_test = y_test.squeeze()\n",
        "type(X_train)"
      ],
      "metadata": {
        "id": "Nz3fQSZdZawX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_test)"
      ],
      "metadata": {
        "id": "Bg9QBFOvZjPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELLING"
      ],
      "metadata": {
        "id": "VclRfDcBcmJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'models'\n",
        "isExisting = os.path.exists(path)\n",
        "if not isExisting:\n",
        "  os.mkdir(path)"
      ],
      "metadata": {
        "id": "L-fU2zzDcjXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training sample size = \", Xb_train.shape[0])\n",
        "print(\"Testing sample size = \", X_test.shape[0])"
      ],
      "metadata": {
        "id": "HGaMfhXKc35T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SUPPORT VECTOR MACHINE (SVM)"
      ],
      "metadata": {
        "id": "xlCpJvn9dOTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a vectorization and modelling pipeline\n",
        "svm_pipeline = Pipeline([\n",
        "     ('vect', CountVectorizer(ngram_range=(1,1))),\n",
        "     ('tfidf', TfidfTransformer()),\n",
        "     ('clf', SVC(kernel = 'sigmoid', random_state=0, gamma='scale', C=1.2, probability=True)), #tunned svm\n",
        " ])"
      ],
      "metadata": {
        "id": "Z41nDC-qdMbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# SVM Algorithm training X_train, X_test, y_train, y_test\n",
        "svm_model = svm_pipeline.fit(Xb_train, yb_train)\n",
        "svm_model"
      ],
      "metadata": {
        "id": "R96wA5K1d1NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aoDj-y9ZiOzc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}